# Data description
1.	My overall research is involved with the large class of per- and polyfluoroalkyl substances (pfas), how they affect and alter the environment and animals, and how we can extract/retrieve them from the environment. My current research topic, however, is focused on perfluoroalkyl betaines and how to remove them from soil sediment. Perfluoroalkyl betaines are straight chained per-fluorinated substances with a betaine headgroup. Betaines are a class of compounds that contain a positively charged nitrogen directly connected to a carbonyl group with a negatively charged oxygen. These compounds dissolve semi-readily in aqueous phases but have a very high sorption factor, so they are found on almost any surface they come into contact with. The main question that the microbiologist from Texas A&M University and I are trying to answer is: can we remove these perfluoroalkyl betaines from soil sediment, and how?

2.	The type of data we need comes in two phases: the first phase is data on the soil we will be using for our tests. We need to know if there is any trace pfas compounds in the soil before spiking with our pfas standards, we need the pH of the soil, the carbon and nitrogen content of the soil, the particle size(s) of the soil, the cationic exchange capacity, and lastly the dominant mineral type of the soil. This data was found previously by one of my lab mates and is less than 1 GB in size.
The second phase is data from the liquid/liquid extraction that would take place to determine if the microbiologists at Texas A&M successfully pulled any perfluoroalkyl betaines out of the soil or not. This data will consist of a large dataset, upwards of 50-100 samples (5-10 GB) and will be focused on the organic layer extracted from the aqueous phase. The goal is that these betaine compounds will move from the aqueous layer to the organic layer after the addition of salt, and possibly an acid or base, to the aqueous phase. These extracted samples will then be run on an LC/MS with a general targeted pfas method. The data collected from the LC/MS analysis will be saved onto an online folder that the whole lab can access. 

![image](https://user-images.githubusercontent.com/104161364/164519020-8995ea35-09ec-4f34-8d21-6d55980536ce.png)

# Roles and Resposiblities
1.	The research project that I’m currently working on has two different aspects to it; my collaborators at Texas A&M University might manage their independent data differently, but our collective data is managed on a google drive that the PI from Texas A&M manages. The data that I produce separate from the collective data is managed quite differently, however. My PI is responsible for the implementation of the DMP on our end, and as of now I oversee all the data produced regarding the non-volatile compounds we are studying. It is solely my responsibility to save the data onto the LC/MS computer, upload it to the processing computer, and to save it onto the labs shared R drive, which is where we put all our data, project information, etc. that is shared with every member of the lab to access. Also, as of now, there is no contingency plan on my end of the project because the only one with responsibility of anything for the project is myself.
2.	The data being produced by me is not sensitive or need to be protected. It is just data on the compounds, and as we learned in class, just data can’t be “protected” or copyrighted. The plan that my colleagues at Texas A&M came up with does need to be protected however, therefore I can’t speak about the process and procedure that they have created until the work is published. 
3.	The data is stored in three different places for this project. The first place is on the LC/MS computer where the raw data goes after being analyzed by the instrument. Then, the data is copied onto the processing computer, where the raw data is saved along with the processed data. Lastly, the processed data is copied and saved onto my labs R drive. The only process that is automated is the data being copied from the LC/MS computer to the processing computer, every other movement of data is done manually. 
4.	The R drive, which is where the final processed data is located, is backed up every 12 hours. Along with the backup of the R drive every 12 hours, my lab also has external hard drives that we upload the whole R drive to every few months. These external hard drives are stored in a lockbox and are only used if data accidentally gets deleted, or we have a breach of the system by an outsider. I also save the processed data onto my own personal computer. So, in total I have anywhere from two to three copies of the processed data, and 4-5 copies of the raw data. When students graduate, their data is still in the R drive untouched for anyone/everyone to utilize. 
![image](https://user-images.githubusercontent.com/104161364/164519088-daacf196-aeb1-44e1-8c59-34227f182bff.png)

# Data standrds and metadata

# Storage and security

# Access and data sharing

# Archiving and preservation
